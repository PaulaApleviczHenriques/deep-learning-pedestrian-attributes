{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwufnHfvfSwv"
      },
      "source": [
        "# Reconhecimento Multirrótulo de Acessórios, Gênero e Cores de Vestuário em Ambientes Dinâmicos\n",
        "\n",
        "Bacharelado em Ciência da Computação / PUCPR\n",
        "2025"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mO7vcKn66m70"
      },
      "source": [
        "## Imports e dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itrIGnaaVQnH"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "import tensorflow_datasets as tfds\n",
        "import os, csv\n",
        "from collections import Counter\n",
        "import random\n",
        "from PIL import Image, ImageOps\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models, transforms\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPukX0EIzZ-r"
      },
      "outputs": [],
      "source": [
        "# DataSet: https://pucpredu-my.sharepoint.com/personal/rayson_santos_pucpr_br/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Frayson%5Fsantos%5Fpucpr%5Fbr%2FDocuments%2FPAR2025%2Ezip&parent=%2Fpersonal%2Frayson%5Fsantos%5Fpucpr%5Fbr%2FDocuments&ga=1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrgPbMP8xjtN"
      },
      "outputs": [],
      "source": [
        "# Baixando o repositório como um arquivo ZIP\n",
        "\n",
        "os.system(\"wget https://github.com/MatheusKozak/Clothing-Detection-Challenge/archive/refs/heads/main.zip -O Clothing-Detection-Challenge.zip\")\n",
        "\n",
        "# Descompacta apenas as pastas training_set e validation_set\n",
        "# Tempo normal para baixar e descompactar é de 3/4 min\n",
        "os.system(\"unzip -j Clothing-Detection-Challenge.zip 'Clothing-Detection-Challenge-main/training_set/*' -d training_set\")\n",
        "os.system(\"unzip -j Clothing-Detection-Challenge.zip 'Clothing-Detection-Challenge-main/validation_set/*' -d validation_set\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "8R3Z5xgWyj1i"
      },
      "source": [
        "## Análise e visualização de conjuntos de dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99n73wGrLUMq"
      },
      "source": [
        "*   COR DAS ROUPAS: as cores disponíveis são preto, azul, marrom, cinza, verde, laranja, rosa, roxo, vermelho, branco e amarelo, representadas pelas etiquetas [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11].\n",
        "*   GÊNERO: classificado como masculino ou feminino, representado por [0, 1]\n",
        "*   BOLSA: indica se há ou não uma bolsa, representado por [0, 1].\n",
        "*   CHAPÉU: indica se há ou não um chapéu, representado por [0, 1]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5IFTWiTyj1i"
      },
      "outputs": [],
      "source": [
        "dict_label_color = {\n",
        "    '1': \"black\",\n",
        "    '2': \"blue\",\n",
        "    '3': \"brown\",\n",
        "    '4': \"gray\",\n",
        "    '5': \"green\",\n",
        "    '6': \"orange\",\n",
        "    '7': \"pink\",\n",
        "    '8': \"purple\",\n",
        "    '9': \"red\",\n",
        "    '10': \"white\",\n",
        "    '11': \"yellow\",\n",
        "}\n",
        "\n",
        "dict_label_binary = {\n",
        "    '0': \"not present\",\n",
        "    '1': \"present\",\n",
        "}\n",
        "\n",
        "dict_label_gender = {\n",
        "    '1': \"female\",\n",
        "    '0': \"male\",\n",
        "}\n",
        "file_content = \"\"\n",
        "\n",
        "# Usando o arquivo de rótulo para traçar a distribuição de classe\n",
        "with open('training_set/training_set.txt', 'r') as f:\n",
        "  file_content = f.read()\n",
        "\n",
        "def plot_class_dist(index , title , dict_labels):\n",
        "  lines = file_content.splitlines()\n",
        "\n",
        "  # Obtenha com segurança o segundo elemento se a linha tiver pelo menos dois elementos após a divisão por vírgula\n",
        "  elements = [line.split(',')[index] for line in lines if line and len(line.split(',')) > 1]\n",
        "\n",
        "\n",
        "  # Mapeie números para colorir nomes\n",
        "  color_names = [dict_labels.get(num, \"unknown\") for num in elements]\n",
        "\n",
        "  # Conte as ocorrências de cada cor\n",
        "  color_counts = Counter(color_names)\n",
        "\n",
        "  print(f'Contagem de {title} {color_counts}\\n Qunatidade {sum(color_counts.values())}')\n",
        "\n",
        "  # Trace a distribuição de cores\n",
        "  plt.figure(figsize=(10, 6))\n",
        "  plt.bar(color_counts.keys(), color_counts.values())\n",
        "  plt.xlabel(\"Cor\")\n",
        "  plt.ylabel(\"Contagem\")\n",
        "  plt.title(f'Distribution of {title}')\n",
        "  plt.xticks(rotation=45, ha='right')\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "plot_class_dist(1 , \"Cor da parte superior\" , dict_label_color)\n",
        "plot_class_dist(2 , \"Cor da parte inferior\" , dict_label_color)\n",
        "plot_class_dist(3 , \"Genero\" , dict_label_gender)\n",
        "plot_class_dist(4 , \"Tem Bolsa\" , dict_label_binary)\n",
        "plot_class_dist(5 , \"Tem Chapéu\" , dict_label_binary)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PW1e1xZ4-_cQ"
      },
      "source": [
        "Vieses:\n",
        "\n",
        "Como há significativamente mais homens neste conjunto de dados, e eles normalmente não usam cores brilhantes, o modelo pode ter um viés maior em direção a cores mais escuras e neutras.\n",
        "\n",
        "E, como podemos ver, entre as cores mais usadas, o preto é a mais prevalente, com uma grande vantagem. No entanto, isso é apenas correlação, não causalidade.\n",
        "\n",
        "Além disso, como há mais homens, e eles não usam bolsas, a variável \"tem bolsa\" também pode ser enviesada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSQ5OLdxvL6S"
      },
      "outputs": [],
      "source": [
        "# Listar todos os arquivos no diretório training_set\n",
        "image_files = [f for f in os.listdir('training_set') if os.path.isfile(os.path.join('training_set', f))]\n",
        "\n",
        "# Selecione algumas imagens aleatórias\n",
        "num_images_to_display = 15\n",
        "random_images = random.sample(image_files, min(num_images_to_display, len(image_files)))\n",
        "\n",
        "# Exibir as imagens\n",
        "plt.figure(figsize=(15, 5))\n",
        "for i, image_name in enumerate(random_images):\n",
        "    image_path = os.path.join('training_set', image_name)\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is not None:\n",
        "        height, width, _ = img.shape\n",
        "        plt.subplot(1, num_images_to_display, i + 1)\n",
        "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "        plt.title(f'imagem {i}\\n{width}x{height}')\n",
        "        plt.axis('off')\n",
        "    else:\n",
        "        print(f\"Não conseguiu ler a imagem: {image_name}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxCO_VGGxPrv"
      },
      "source": [
        "## Divisão de conjunto de dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-uRh4zxABou"
      },
      "source": [
        "Somando os dois conjuntos de dados, temos 106.756 imagens.\n",
        "\n",
        "Temos uma divisão de conjunto de dados apenas para validação com 12.462 imagens.\n",
        "\n",
        "Então, nossa divisão é 90/10, decidida pelo PAR2025."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsNg9WltzYey"
      },
      "outputs": [],
      "source": [
        "random.shuffle(image_files)\n",
        "\n",
        "total_files = len(image_files)\n",
        "\n",
        "\n",
        "train_split = int(0.9 * total_files*0.1)\n",
        "smaller_for_test = image_files[:train_split]\n",
        "\n",
        "total_files_small = len(smaller_for_test)\n",
        "train_split = int(0.9 * total_files_small)\n",
        "\n",
        "\n",
        "train_files = smaller_for_test[:train_split]\n",
        "test_files = smaller_for_test[train_split:]\n",
        "\n",
        "print(f\"Total de imagens: {total_files}\")\n",
        "print(f\"Treino: {len(train_files)}\")\n",
        "print(f\"Teste: {len(test_files)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KO8LN3MgzkFD"
      },
      "source": [
        "## Padronizando os tamanhos da imagem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmSXrHwKYiqx"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = 128\n",
        "SEED = 42\n",
        "SRC_DIR = \"training_set\"\n",
        "OUT_TRAIN = f\"training_set_resized_{IMAGE_SIZE}\"\n",
        "OUT_TEST  = f\"teste_set_resized_{IMAGE_SIZE}\"\n",
        "VALID_EXT = (\".jpg\", \".jpeg\", \".png\")\n",
        "\n",
        "class PadToSquare:\n",
        "    def __call__(self, img: Image.Image) -> Image.Image:\n",
        "        w, h = img.size\n",
        "        if w == h:\n",
        "            return img\n",
        "        side = max(w, h)\n",
        "        dw = (side - w) // 2\n",
        "        dh = (side - h) // 2\n",
        "        padding = (dw, dh, side - w - dw, side - h - dh)\n",
        "        return ImageOps.expand(img, padding, fill=0)\n",
        "\n",
        "def ensure_dir(path: str):\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "def save_processed(img_path: str, dst_root: str, image_size: int, padder: PadToSquare):\n",
        "    ensure_dir(dst_root)\n",
        "    base = os.path.splitext(os.path.basename(img_path))[0]\n",
        "    ext = \".jpg\"\n",
        "    out_path = os.path.join(dst_root, base + ext)\n",
        "    i = 1\n",
        "    while os.path.exists(out_path):\n",
        "        out_path = os.path.join(dst_root, f\"{base}_{i}{ext}\")\n",
        "        i += 1\n",
        "    img = Image.open(img_path).convert(\"RGB\")\n",
        "    img = padder(img)\n",
        "    img = img.resize((image_size, image_size), Image.BILINEAR)\n",
        "    img.save(out_path, quality=95)\n",
        "    return out_path\n",
        "\n",
        "def preview(paths, k, title):\n",
        "    if not paths:\n",
        "        print(f\"Sem imagens para preview: {title}\")\n",
        "        return\n",
        "    sample = random.sample(paths, min(k, len(paths)))\n",
        "    cols = min(4, k)\n",
        "    rows = (len(sample) + cols - 1) // cols\n",
        "    plt.figure(figsize=(4*cols, 4*rows))\n",
        "    for i, p in enumerate(sample):\n",
        "        plt.subplot(rows, cols, i+1)\n",
        "        plt.imshow(Image.open(p))\n",
        "        plt.title(os.path.basename(p), fontsize=8)\n",
        "        plt.axis(\"off\")\n",
        "    plt.suptitle(title)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def process_like_old_snippet():\n",
        "    random.seed(SEED)\n",
        "    padder = PadToSquare()\n",
        "\n",
        "    image_files = [\n",
        "        f for f in os.listdir(SRC_DIR)\n",
        "        if os.path.isfile(os.path.join(SRC_DIR, f)) and f.lower().endswith(VALID_EXT)\n",
        "    ]\n",
        "    total_files = len(image_files)\n",
        "    if total_files == 0:\n",
        "        print(\"Sem imagens na raiz de 'training_set'.\")\n",
        "        return\n",
        "\n",
        "    random.shuffle(image_files)\n",
        "\n",
        "    # 9% do total\n",
        "\n",
        "    sub_set_size = 1\n",
        "    subset_len = int(0.9 * total_files * sub_set_size)\n",
        "    sub_set = image_files[:subset_len]\n",
        "\n",
        "    # Split 90/10 desntro desse subconjunto\n",
        "    total_files_small = len(sub_set)\n",
        "    train_len = int(0.9 * total_files_small)\n",
        "    train_files = sub_set[:train_len]\n",
        "    test_files  = sub_set[train_len:]\n",
        "\n",
        "    ensure_dir(OUT_TRAIN); ensure_dir(OUT_TEST)\n",
        "    out_train_paths, out_test_paths = [], []\n",
        "\n",
        "    for fname in train_files:\n",
        "        src_path = os.path.join(SRC_DIR, fname)\n",
        "        try:\n",
        "            out_train_paths.append(save_processed(src_path, OUT_TRAIN, IMAGE_SIZE, padder))\n",
        "        except Exception as e:\n",
        "            print(\"Erro (train):\", src_path, e)\n",
        "\n",
        "    for fname in test_files:\n",
        "        src_path = os.path.join(SRC_DIR, fname)\n",
        "        try:\n",
        "            out_test_paths.append(save_processed(src_path, OUT_TEST, IMAGE_SIZE, padder))\n",
        "        except Exception as e:\n",
        "            print(\"Erro (test):\", src_path, e)\n",
        "\n",
        "    print(f\"Total de imagens (origem): {total_files}\")\n",
        "    print(f\"Subconjunto usado (≈9%):  {total_files_small}\")\n",
        "    print(f\"Treino (90% do subset):   {len(out_train_paths)} -> {OUT_TRAIN}\")\n",
        "    print(f\"Teste  (10% do subset):   {len(out_test_paths)}  -> {OUT_TEST}\")\n",
        "\n",
        "    preview(out_train_paths, 4, \"Preview - 4 aleatórias (Treino)\")\n",
        "    preview(out_test_paths,  4, \"Preview - 4 aleatórias (Teste)\")\n",
        "\n",
        "\n",
        "process_like_old_snippet()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBPcwjCtmx1f"
      },
      "source": [
        "## Deep learning - CNN - ResNet18\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJxhj9-JLTWA"
      },
      "outputs": [],
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "TRAIN_DIR = OUT_TRAIN\n",
        "TEST_DIR  = OUT_TEST\n",
        "TRAIN_TXT = \"training_set/training_set.txt\"\n",
        "TEST_TXT  = \"training_set/training_set.txt\"\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 5\n",
        "LR = 1e-4\n",
        "TOP_COL_IDX = 1\n",
        "BOTTOM_COL_IDX = 2\n",
        "GENDER_COL_IDX = 3\n",
        "BAG_COL_IDX = 4\n",
        "HAT_COL_IDX = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyFwtV3g4J1u"
      },
      "source": [
        "### Parte superior da roupa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xN27ecGlm2X4"
      },
      "outputs": [],
      "source": [
        "NUM_CLASSES = 11\n",
        "\n",
        "def load_topcolor_labels(txt_path):\n",
        "    mapping = {}\n",
        "    with open(txt_path, \"r\") as f:\n",
        "        reader = csv.reader(f)\n",
        "        for row in reader:\n",
        "            if not row or len(row) < 2:\n",
        "                continue\n",
        "            fname = row[0].strip()\n",
        "            top_color_1_11 = int(row[1].strip())\n",
        "            mapping[fname] = top_color_1_11 - 1\n",
        "    return mapping\n",
        "\n",
        "train_labels = load_topcolor_labels(TRAIN_TXT)\n",
        "test_labels  = load_topcolor_labels(TEST_TXT)\n",
        "\n",
        "def list_labeled_files(img_dir, labels_dict):\n",
        "    files = [f for f in os.listdir(img_dir) if f.lower().endswith((\".jpg\",\".jpeg\",\".png\"))]\n",
        "    keep  = [f for f in files if f in labels_dict]\n",
        "    return keep\n",
        "\n",
        "train_files = list_labeled_files(TRAIN_DIR, train_labels)\n",
        "test_files  = list_labeled_files(TEST_DIR,  test_labels)\n",
        "\n",
        "if len(train_files) == 0 or len(test_files) == 0:\n",
        "    raise RuntimeError(\"Algum split ficou vazio após cruzar arquivos com rótulos. Verifique nomes e paths.\")\n",
        "\n",
        "train_tfms = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
        "                         std=[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "test_tfms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
        "                         std=[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "class TopColorDataset(Dataset):\n",
        "    def __init__(self, file_list, labels_dict, root_dir, transform=None):\n",
        "        self.file_list = file_list\n",
        "        self.labels_dict = labels_dict\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self): return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fname = self.file_list[idx]\n",
        "        path = os.path.join(self.root_dir, fname)\n",
        "        img = Image.open(path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        label = self.labels_dict[fname]\n",
        "        return img, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "train_ds = TopColorDataset(train_files, train_labels, TRAIN_DIR, transform=train_tfms)\n",
        "test_ds  = TopColorDataset(test_files,  test_labels,  TEST_DIR,  transform=test_tfms)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "print(f\"Train: {len(train_ds)} | Test: {len(test_ds)}\")\n",
        "\n",
        "# Usa pesos pré-treinados do ImageNet\n",
        "def create_model(num_classes=11):\n",
        "    model = models.resnet18(weights='IMAGENET1K_V1')\n",
        "    in_feats = model.fc.in_features\n",
        "    model.fc = nn.Linear(in_feats, num_classes)\n",
        "    return model\n",
        "\n",
        "model = create_model(NUM_CLASSES).to(DEVICE)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "def run_epoch(model, loader, train_mode=True):\n",
        "    model.train() if train_mode else model.eval()\n",
        "    total_loss, correct, total = 0.0, 0, 0\n",
        "    with torch.set_grad_enabled(train_mode):\n",
        "        for imgs, labels in loader:\n",
        "            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
        "            if train_mode: optimizer.zero_grad()\n",
        "            logits = model(imgs)\n",
        "            loss = criterion(logits, labels)\n",
        "            if train_mode:\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "            total_loss += loss.item() * imgs.size(0)\n",
        "            preds = logits.argmax(dim=1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    return total_loss/total, correct/total\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    tr_loss, tr_acc = run_epoch(model, train_loader, train_mode=True)\n",
        "    te_loss, te_acc = run_epoch(model, test_loader,  train_mode=False)\n",
        "    print(f\"Epoch {epoch:02d}/{EPOCHS} | Train: {tr_acc*100:.1f}% | Test: {te_acc*100:.1f}%\")\n",
        "\n",
        "print(f\"\\nAcurácia final: {te_acc*100:.1f}%\")\n",
        "\n",
        "model.eval()\n",
        "y_true, y_pred = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in test_loader:\n",
        "        imgs = imgs.to(DEVICE)\n",
        "        logits = model(imgs)\n",
        "        preds = logits.argmax(dim=1).cpu().numpy()\n",
        "        y_pred.extend(preds)\n",
        "        y_true.extend(labels.numpy())\n",
        "\n",
        "y_true = np.array(y_true)\n",
        "y_pred = np.array(y_pred)\n",
        "\n",
        "class_names = [\"preto\",\"branco\",\"azul\",\"vermelho\",\"verde\",\n",
        "               \"amarelo\",\"marrom\",\"rosa\",\"roxo\",\"cinza\",\"laranja\"]\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred, labels=list(range(NUM_CLASSES)))\n",
        "cm_norm = cm.astype(float) / (cm.sum(axis=1, keepdims=True) + 1e-12)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(cm_norm, interpolation=\"nearest\", cmap='Blues')\n",
        "plt.title(f\"Matriz de Confusão – Cores da Parte Superior (Acc: {te_acc*100:.1f}%)\")\n",
        "plt.xticks(ticks=np.arange(NUM_CLASSES), labels=class_names, rotation=45, ha=\"right\")\n",
        "plt.yticks(ticks=np.arange(NUM_CLASSES), labels=class_names)\n",
        "plt.xlabel(\"Predito\")\n",
        "plt.ylabel(\"Real\")\n",
        "\n",
        "for i in range(NUM_CLASSES):\n",
        "    for j in range(NUM_CLASSES):\n",
        "        if cm_norm[i, j] > 0.01:\n",
        "            color = 'white' if cm_norm[i, j] > 0.5 else 'black'\n",
        "            plt.text(j, i, f\"{cm_norm[i, j]*100:.0f}%\",\n",
        "                    ha=\"center\", va=\"center\", color=color, fontsize=8)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JLesR3S31lO"
      },
      "source": [
        "### Parte inferior da roupa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdRArc95335u"
      },
      "outputs": [],
      "source": [
        "NUM_CLASSES = 11\n",
        "\n",
        "def load_bottomcolor_labels(txt_path, col_idx=BOTTOM_COL_IDX):\n",
        "    mapping = {}\n",
        "    with open(txt_path, \"r\") as f:\n",
        "        reader = csv.reader(f)\n",
        "        for row in reader:\n",
        "            if not row or len(row) <= col_idx:\n",
        "                continue\n",
        "            fname = row[0].strip()\n",
        "            bottom_color_1_11 = int(row[col_idx].strip())\n",
        "            mapping[fname] = bottom_color_1_11 - 1\n",
        "    return mapping\n",
        "\n",
        "train_labels = load_bottomcolor_labels(TRAIN_TXT)\n",
        "test_labels  = load_bottomcolor_labels(TEST_TXT)\n",
        "\n",
        "def list_labeled_files(img_dir, labels_dict):\n",
        "    files = [f for f in os.listdir(img_dir) if f.lower().endswith((\".jpg\",\".jpeg\",\".png\"))]\n",
        "    keep  = [f for f in files if f in labels_dict]\n",
        "    return keep\n",
        "\n",
        "train_files = list_labeled_files(TRAIN_DIR, train_labels)\n",
        "test_files  = list_labeled_files(TEST_DIR,  test_labels)\n",
        "\n",
        "if len(train_files) == 0 or len(test_files) == 0:\n",
        "    raise RuntimeError(\"Algum split ficou vazio após cruzar arquivos com rótulos. Verifique nomes e paths.\")\n",
        "\n",
        "train_tfms = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
        "                         std=[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "test_tfms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
        "                         std=[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "class TopColorDataset(Dataset):\n",
        "    def __init__(self, file_list, labels_dict, root_dir, transform=None):\n",
        "        self.file_list = file_list\n",
        "        self.labels_dict = labels_dict\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self): return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fname = self.file_list[idx]\n",
        "        path = os.path.join(self.root_dir, fname)\n",
        "        img = Image.open(path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        label = self.labels_dict[fname]\n",
        "        return img, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "train_ds = TopColorDataset(train_files, train_labels, TRAIN_DIR, transform=train_tfms)\n",
        "test_ds  = TopColorDataset(test_files,  test_labels,  TEST_DIR,  transform=test_tfms)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "print(f\"Train: {len(train_ds)} | Test: {len(test_ds)}\")\n",
        "\n",
        "# Usa pesos pré-treinados do ImageNet\n",
        "def create_model(num_classes=11):\n",
        "    model = models.resnet18(weights='IMAGENET1K_V1')\n",
        "    in_feats = model.fc.in_features\n",
        "    model.fc = nn.Linear(in_feats, num_classes)\n",
        "    return model\n",
        "\n",
        "model = create_model(NUM_CLASSES).to(DEVICE)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "def run_epoch(model, loader, train_mode=True):\n",
        "    model.train() if train_mode else model.eval()\n",
        "    total_loss, correct, total = 0.0, 0, 0\n",
        "    with torch.set_grad_enabled(train_mode):\n",
        "        for imgs, labels in loader:\n",
        "            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
        "            if train_mode: optimizer.zero_grad()\n",
        "            logits = model(imgs)\n",
        "            loss = criterion(logits, labels)\n",
        "            if train_mode:\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "            total_loss += loss.item() * imgs.size(0)\n",
        "            preds = logits.argmax(dim=1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    return total_loss/total, correct/total\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    tr_loss, tr_acc = run_epoch(model, train_loader, train_mode=True)\n",
        "    te_loss, te_acc = run_epoch(model, test_loader,  train_mode=False)\n",
        "    print(f\"Epoch {epoch:02d}/{EPOCHS} | Train: {tr_acc*100:.1f}% | Test: {te_acc*100:.1f}%\")\n",
        "\n",
        "print(f\"\\nAcurácia final: {te_acc*100:.1f}%\")\n",
        "\n",
        "model.eval()\n",
        "y_true, y_pred = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in test_loader:\n",
        "        imgs = imgs.to(DEVICE)\n",
        "        logits = model(imgs)\n",
        "        preds = logits.argmax(dim=1).cpu().numpy()\n",
        "        y_pred.extend(preds)\n",
        "        y_true.extend(labels.numpy())\n",
        "\n",
        "y_true = np.array(y_true)\n",
        "y_pred = np.array(y_pred)\n",
        "\n",
        "class_names = [\"preto\",\"branco\",\"azul\",\"vermelho\",\"verde\",\n",
        "               \"amarelo\",\"marrom\",\"rosa\",\"roxo\",\"cinza\",\"laranja\"]\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred, labels=list(range(NUM_CLASSES)))\n",
        "cm_norm = cm.astype(float) / (cm.sum(axis=1, keepdims=True) + 1e-12)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(cm_norm, interpolation=\"nearest\", cmap='Blues')\n",
        "plt.title(f\"Matriz de Confusão – Cores da Parte Inferior (Acc: {te_acc*100:.1f}%)\")\n",
        "plt.xticks(ticks=np.arange(NUM_CLASSES), labels=class_names, rotation=45, ha=\"right\")\n",
        "plt.yticks(ticks=np.arange(NUM_CLASSES), labels=class_names)\n",
        "plt.xlabel(\"Predito\")\n",
        "plt.ylabel(\"Real\")\n",
        "\n",
        "for i in range(NUM_CLASSES):\n",
        "    for j in range(NUM_CLASSES):\n",
        "        if cm_norm[i, j] > 0.01:\n",
        "            color = 'white' if cm_norm[i, j] > 0.5 else 'black'\n",
        "            plt.text(j, i, f\"{cm_norm[i, j]*100:.0f}%\",\n",
        "                    ha=\"center\", va=\"center\", color=color, fontsize=8)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ER1iGwyO36u6"
      },
      "source": [
        "### Gênero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVJHvNmJ35zv"
      },
      "outputs": [],
      "source": [
        "NUM_CLASSES = 2\n",
        "\n",
        "def load_gender_labels(txt_path, col_idx=GENDER_COL_IDX):\n",
        "    mapping = {}\n",
        "    with open(txt_path, \"r\") as f:\n",
        "        reader = csv.reader(f)\n",
        "        for row in reader:\n",
        "            if not row or len(row) <= col_idx:\n",
        "                continue\n",
        "            fname = row[0].strip()\n",
        "            gender_0_1 = int(row[col_idx].strip())\n",
        "            mapping[fname] = gender_0_1\n",
        "    return mapping\n",
        "\n",
        "train_labels = load_gender_labels(TRAIN_TXT)\n",
        "test_labels  = load_gender_labels(TEST_TXT)\n",
        "\n",
        "def list_labeled_files(img_dir, labels_dict):\n",
        "    files = [f for f in os.listdir(img_dir) if f.lower().endswith((\".jpg\",\".jpeg\",\".png\"))]\n",
        "    keep  = [f for f in files if f in labels_dict]\n",
        "    return keep\n",
        "\n",
        "train_files = list_labeled_files(TRAIN_DIR, train_labels)\n",
        "test_files  = list_labeled_files(TEST_DIR,  test_labels)\n",
        "\n",
        "if len(train_files) == 0 or len(test_files) == 0:\n",
        "    raise RuntimeError(\"Algum split ficou vazio após cruzar arquivos com rótulos. Verifique nomes e paths.\")\n",
        "\n",
        "train_tfms = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
        "                         std=[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "test_tfms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
        "                         std=[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "class TopColorDataset(Dataset):\n",
        "    def __init__(self, file_list, labels_dict, root_dir, transform=None):\n",
        "        self.file_list = file_list\n",
        "        self.labels_dict = labels_dict\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self): return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fname = self.file_list[idx]\n",
        "        path = os.path.join(self.root_dir, fname)\n",
        "        img = Image.open(path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        label = self.labels_dict[fname]\n",
        "        return img, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "train_ds = TopColorDataset(train_files, train_labels, TRAIN_DIR, transform=train_tfms)\n",
        "test_ds  = TopColorDataset(test_files,  test_labels,  TEST_DIR,  transform=test_tfms)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "print(f\"Train: {len(train_ds)} | Test: {len(test_ds)}\")\n",
        "\n",
        "# Usa pesos pré-treinados do ImageNet\n",
        "def create_model(num_classes=NUM_CLASSES):\n",
        "    model = models.resnet18(weights='IMAGENET1K_V1')\n",
        "    in_feats = model.fc.in_features\n",
        "    model.fc = nn.Linear(in_feats, num_classes)\n",
        "    return model\n",
        "\n",
        "model = create_model(NUM_CLASSES).to(DEVICE)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "def run_epoch(model, loader, train_mode=True):\n",
        "    model.train() if train_mode else model.eval()\n",
        "    total_loss, correct, total = 0.0, 0, 0\n",
        "    with torch.set_grad_enabled(train_mode):\n",
        "        for imgs, labels in loader:\n",
        "            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
        "            if train_mode: optimizer.zero_grad()\n",
        "            logits = model(imgs)\n",
        "            loss = criterion(logits, labels)\n",
        "            if train_mode:\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "            total_loss += loss.item() * imgs.size(0)\n",
        "            preds = logits.argmax(dim=1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    return total_loss/total, correct/total\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    tr_loss, tr_acc = run_epoch(model, train_loader, train_mode=True)\n",
        "    te_loss, te_acc = run_epoch(model, test_loader,  train_mode=False)\n",
        "    print(f\"Epoch {epoch:02d}/{EPOCHS} | Train: {tr_acc*100:.1f}% | Test: {te_acc*100:.1f}%\")\n",
        "\n",
        "print(f\"\\nAcurácia final: {te_acc*100:.1f}%\")\n",
        "\n",
        "model.eval()\n",
        "y_true, y_pred = [], []\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in test_loader:\n",
        "        imgs = imgs.to(DEVICE)\n",
        "        preds = model(imgs).argmax(dim=1).cpu().numpy()\n",
        "        y_pred.extend(preds)\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "\n",
        "y_true = np.array(y_true)\n",
        "y_pred = np.array(y_pred)\n",
        "\n",
        "class_names = [\"masculino\", \"feminino\"]\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred, labels=list(range(NUM_CLASSES)))\n",
        "cm_norm = cm.astype(float) / (cm.sum(axis=1, keepdims=True) + 1e-12)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(cm_norm, interpolation=\"nearest\", cmap='Blues')\n",
        "plt.title(f\"Matriz de Confusão – Gênero (Acc: {te_acc*100:.1f}%)\")\n",
        "plt.xticks(ticks=np.arange(NUM_CLASSES), labels=class_names, rotation=0, ha=\"center\")\n",
        "plt.yticks(ticks=np.arange(NUM_CLASSES), labels=class_names)\n",
        "plt.xlabel(\"Predito\")\n",
        "plt.ylabel(\"Real\")\n",
        "\n",
        "for i in range(NUM_CLASSES):\n",
        "    for j in range(NUM_CLASSES):\n",
        "        color = 'white' if cm_norm[i, j] > 0.5 else 'black'\n",
        "        plt.text(j, i, f\"{cm_norm[i, j]*100:.0f}%\",\n",
        "                ha=\"center\", va=\"center\", color=color)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_H9bgdtt399q"
      },
      "source": [
        "### Bolsa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OnpgHRMS3_Sf"
      },
      "outputs": [],
      "source": [
        "NUM_CLASSES = 2\n",
        "\n",
        "def load_bag_labels(txt_path, col_idx=BAG_COL_IDX):\n",
        "    mapping = {}\n",
        "    with open(txt_path, \"r\") as f:\n",
        "        reader = csv.reader(f)\n",
        "        for row in reader:\n",
        "            if not row or len(row) <= col_idx:\n",
        "                continue\n",
        "            fname = row[0].strip()\n",
        "            bag_0_1 = int(row[col_idx].strip())  # 0/1\n",
        "            mapping[fname] = bag_0_1\n",
        "    return mapping\n",
        "\n",
        "train_labels = load_bag_labels(TRAIN_TXT)\n",
        "test_labels  = load_bag_labels(TEST_TXT)\n",
        "\n",
        "def list_labeled_files(img_dir, labels_dict):\n",
        "    files = [f for f in os.listdir(img_dir) if f.lower().endswith((\".jpg\",\".jpeg\",\".png\"))]\n",
        "    keep  = [f for f in files if f in labels_dict]\n",
        "    return keep\n",
        "\n",
        "train_files = list_labeled_files(TRAIN_DIR, train_labels)\n",
        "test_files  = list_labeled_files(TEST_DIR,  test_labels)\n",
        "\n",
        "if len(train_files) == 0 or len(test_files) == 0:\n",
        "    raise RuntimeError(\"Algum split ficou vazio após cruzar arquivos com rótulos. Verifique nomes e paths.\")\n",
        "\n",
        "train_tfms = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
        "                         std=[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "test_tfms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
        "                         std=[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "class TopColorDataset(Dataset):\n",
        "    def __init__(self, file_list, labels_dict, root_dir, transform=None):\n",
        "        self.file_list = file_list\n",
        "        self.labels_dict = labels_dict\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self): return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fname = self.file_list[idx]\n",
        "        path = os.path.join(self.root_dir, fname)\n",
        "        img = Image.open(path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        label = self.labels_dict[fname]\n",
        "        return img, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "train_ds = TopColorDataset(train_files, train_labels, TRAIN_DIR, transform=train_tfms)\n",
        "test_ds  = TopColorDataset(test_files,  test_labels,  TEST_DIR,  transform=test_tfms)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "print(f\"Train: {len(train_ds)} | Test: {len(test_ds)}\")\n",
        "\n",
        "# Usa pesos pré-treinados do ImageNet\n",
        "def create_model(num_classes=NUM_CLASSES):\n",
        "    model = models.resnet18(weights='IMAGENET1K_V1')\n",
        "    in_feats = model.fc.in_features\n",
        "    model.fc = nn.Linear(in_feats, num_classes)\n",
        "    return model\n",
        "\n",
        "model = create_model(NUM_CLASSES).to(DEVICE)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "def run_epoch(model, loader, train_mode=True):\n",
        "    model.train() if train_mode else model.eval()\n",
        "    total_loss, correct, total = 0.0, 0, 0\n",
        "    with torch.set_grad_enabled(train_mode):\n",
        "        for imgs, labels in loader:\n",
        "            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
        "            if train_mode: optimizer.zero_grad()\n",
        "            logits = model(imgs)\n",
        "            loss = criterion(logits, labels)\n",
        "            if train_mode:\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "            total_loss += loss.item() * imgs.size(0)\n",
        "            preds = logits.argmax(dim=1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    return total_loss/total, correct/total\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    tr_loss, tr_acc = run_epoch(model, train_loader, train_mode=True)\n",
        "    te_loss, te_acc = run_epoch(model, test_loader,  train_mode=False)\n",
        "    print(f\"Epoch {epoch:02d}/{EPOCHS} | Train: {tr_acc*100:.1f}% | Test: {te_acc*100:.1f}%\")\n",
        "\n",
        "print(f\"\\nAcurácia final: {te_acc*100:.1f}%\")\n",
        "\n",
        "model.eval()\n",
        "y_true, y_pred = [], []\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in test_loader:\n",
        "        imgs = imgs.to(DEVICE)\n",
        "        preds = model(imgs).argmax(dim=1).cpu().numpy()\n",
        "        y_pred.extend(preds)\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "\n",
        "y_true = np.array(y_true)\n",
        "y_pred = np.array(y_pred)\n",
        "\n",
        "class_names = [\"sem bolsa\", \"com bolsa\"]\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred, labels=list(range(NUM_CLASSES)))\n",
        "cm_norm = cm.astype(float) / (cm.sum(axis=1, keepdims=True) + 1e-12)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(cm_norm, interpolation=\"nearest\", cmap='Blues')\n",
        "plt.title(f\"Matriz de Confusão – Bolsa (Acc: {te_acc*100:.1f}%)\")\n",
        "plt.xticks(ticks=np.arange(NUM_CLASSES), labels=class_names, rotation=0, ha=\"center\")\n",
        "plt.yticks(ticks=np.arange(NUM_CLASSES), labels=class_names)\n",
        "plt.xlabel(\"Predito\")\n",
        "plt.ylabel(\"Real\")\n",
        "\n",
        "for i in range(NUM_CLASSES):\n",
        "    for j in range(NUM_CLASSES):\n",
        "        color = 'white' if cm_norm[i, j] > 0.5 else 'black'\n",
        "        plt.text(j, i, f\"{cm_norm[i, j]*100:.0f}%\",\n",
        "                ha=\"center\", va=\"center\", color=color)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rRXspp64AzI"
      },
      "source": [
        "### Chapéu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jj9CiU7_4CDo"
      },
      "outputs": [],
      "source": [
        "NUM_CLASSES = 2\n",
        "\n",
        "def load_hat_labels(txt_path, col_idx=HAT_COL_IDX):\n",
        "    mapping = {}\n",
        "    with open(txt_path, \"r\") as f:\n",
        "        reader = csv.reader(f)\n",
        "        for row in reader:\n",
        "            if not row or len(row) <= col_idx:\n",
        "                continue\n",
        "            fname = row[0].strip()\n",
        "            hat_0_1 = int(row[col_idx].strip())\n",
        "            mapping[fname] = hat_0_1\n",
        "    return mapping\n",
        "\n",
        "train_labels = load_hat_labels(TRAIN_TXT)\n",
        "test_labels  = load_hat_labels(TEST_TXT)\n",
        "\n",
        "def list_labeled_files(img_dir, labels_dict):\n",
        "    files = [f for f in os.listdir(img_dir) if f.lower().endswith((\".jpg\",\".jpeg\",\".png\"))]\n",
        "    keep  = [f for f in files if f in labels_dict]\n",
        "    return keep\n",
        "\n",
        "train_files = list_labeled_files(TRAIN_DIR, train_labels)\n",
        "test_files  = list_labeled_files(TEST_DIR,  test_labels)\n",
        "\n",
        "if len(train_files) == 0 or len(test_files) == 0:\n",
        "    raise RuntimeError(\"Algum split ficou vazio após cruzar arquivos com rótulos. Verifique nomes e paths.\")\n",
        "\n",
        "train_tfms = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
        "                         std=[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "test_tfms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
        "                         std=[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "class TopColorDataset(Dataset):\n",
        "    def __init__(self, file_list, labels_dict, root_dir, transform=None):\n",
        "        self.file_list = file_list\n",
        "        self.labels_dict = labels_dict\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self): return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fname = self.file_list[idx]\n",
        "        path = os.path.join(self.root_dir, fname)\n",
        "        img = Image.open(path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        label = self.labels_dict[fname]\n",
        "        return img, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "train_ds = TopColorDataset(train_files, train_labels, TRAIN_DIR, transform=train_tfms)\n",
        "test_ds  = TopColorDataset(test_files,  test_labels,  TEST_DIR,  transform=test_tfms)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "print(f\"Train: {len(train_ds)} | Test: {len(test_ds)}\")\n",
        "\n",
        "# Usa pesos pré-treinados do ImageNet\n",
        "def create_model(num_classes=NUM_CLASSES):\n",
        "    model = models.resnet18(weights='IMAGENET1K_V1')\n",
        "    in_feats = model.fc.in_features\n",
        "    model.fc = nn.Linear(in_feats, num_classes)\n",
        "    return model\n",
        "\n",
        "model = create_model(NUM_CLASSES).to(DEVICE)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "def run_epoch(model, loader, train_mode=True):\n",
        "    model.train() if train_mode else model.eval()\n",
        "    total_loss, correct, total = 0.0, 0, 0\n",
        "    with torch.set_grad_enabled(train_mode):\n",
        "        for imgs, labels in loader:\n",
        "            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
        "            if train_mode: optimizer.zero_grad()\n",
        "            logits = model(imgs)\n",
        "            loss = criterion(logits, labels)\n",
        "            if train_mode:\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "            total_loss += loss.item() * imgs.size(0)\n",
        "            preds = logits.argmax(dim=1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    return total_loss/total, correct/total\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    tr_loss, tr_acc = run_epoch(model, train_loader, train_mode=True)\n",
        "    te_loss, te_acc = run_epoch(model, test_loader,  train_mode=False)\n",
        "    print(f\"Epoch {epoch:02d}/{EPOCHS} | Train: {tr_acc*100:.1f}% | Test: {te_acc*100:.1f}%\")\n",
        "\n",
        "print(f\"\\nAcurácia final: {te_acc*100:.1f}%\")\n",
        "\n",
        "model.eval()\n",
        "y_true, y_pred = [], []\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in test_loader:\n",
        "        imgs = imgs.to(DEVICE)\n",
        "        preds = model(imgs).argmax(dim=1).cpu().numpy()\n",
        "        y_pred.extend(preds)\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "\n",
        "y_true = np.array(y_true)\n",
        "y_pred = np.array(y_pred)\n",
        "\n",
        "class_names = [\"sem chapéu\", \"com chapéu\"]\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred, labels=list(range(NUM_CLASSES)))\n",
        "cm_norm = cm.astype(float) / (cm.sum(axis=1, keepdims=True) + 1e-12)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(cm_norm, interpolation=\"nearest\", cmap='Blues')\n",
        "plt.title(f\"Matriz de Confusão – Chapéu (Acc: {te_acc*100:.1f}%)\")\n",
        "plt.xticks(ticks=np.arange(NUM_CLASSES), labels=class_names, rotation=0, ha=\"center\")\n",
        "plt.yticks(ticks=np.arange(NUM_CLASSES), labels=class_names)\n",
        "plt.xlabel(\"Predito\")\n",
        "plt.ylabel(\"Real\")\n",
        "\n",
        "for i in range(NUM_CLASSES):\n",
        "    for j in range(NUM_CLASSES):\n",
        "        color = 'white' if cm_norm[i, j] > 0.5 else 'black'\n",
        "        plt.text(j, i, f\"{cm_norm[i, j]*100:.0f}%\",\n",
        "                ha=\"center\", va=\"center\", color=color)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "mO7vcKn66m70",
        "8R3Z5xgWyj1i",
        "pxCO_VGGxPrv",
        "KO8LN3MgzkFD",
        "nyFwtV3g4J1u",
        "8JLesR3S31lO",
        "ER1iGwyO36u6",
        "_H9bgdtt399q",
        "8rRXspp64AzI"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}