# -*- coding: utf-8 -*-
"""5-CNN-ResNet18&EfficientNetB0-todos.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_w5QpnNvhOjb7UWjC40GURW4QwzLrsIk

# Reconhecimento Multirrótulo de Acessórios, Gênero e Cores de Vestuário em Ambientes Dinâmicos

Bacharelado em Ciência da Computação / PUCPR

2025

## Imports e dataset
"""

from google.colab import drive
import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image, ImageOps
import os
from tabulate import tabulate

"""## Deep learning - CNN

## Usando o modelo ja treinado - CNN - ResNet18 e EfficientNet B0
"""

drive.mount('/content/drive')

"""### Com todos os atributos juntos"""

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
MODEL_PATH_EFFICIENT = '/content/drive/MyDrive/Ciência da Computação/Experiência Criativa: Projeto Transformador II/best_efficientnet_multitask.pth'
MODEL_PATH_RESNET = '/content/drive/MyDrive/Ciência da Computação/Experiência Criativa: Projeto Transformador II/best_multitask_resnet18_state.pth'
IMAGES_DIR = "/content/drive/MyDrive/Ciência da Computação/Experiência Criativa: Projeto Transformador II/imagens_qualidade_reduzida"

COLOR_LABELS = {
    0: "Preto", 1: "Branco", 2: "Vermelho", 3: "Roxo", 4: "Amarelo",
    5: "Cinza", 6: "Azul", 7: "Verde", 8: "Laranja", 9: "Marrom", 10: "Rosa"
}
GENDER_LABELS = {0: "Masculino", 1: "Feminino"}
BINARY_LABELS = {0: "Não", 1: "Sim"}


class EfficientNetMultiTask(nn.Module):
    def __init__(self):
        super(EfficientNetMultiTask, self).__init__()
        efficientnet = models.efficientnet_b0(weights='IMAGENET1K_V1')
        self.backbone = nn.Sequential(*list(efficientnet.children())[:-1])

        self.fc_top_color = nn.Linear(1280, 11)
        self.fc_bottom_color = nn.Linear(1280, 11)
        self.fc_gender = nn.Linear(1280, 2)
        self.fc_bag = nn.Linear(1280, 2)
        self.fc_hat = nn.Linear(1280, 2)

    def forward(self, x):
        features = self.backbone(x)
        features = features.view(features.size(0), -1)

        return {
            'top_color': self.fc_top_color(features),
            'bottom_color': self.fc_bottom_color(features),
            'gender': self.fc_gender(features),
            'bag': self.fc_bag(features),
            'hat': self.fc_hat(features)
        }

class ResNetMultiTask(nn.Module):
    def __init__(self):
        super(ResNetMultiTask, self).__init__()
        resnet = models.resnet18(weights='IMAGENET1K_V1')
        self.backbone = nn.Sequential(*list(resnet.children())[:-1])

        self.fc_top_color = nn.Linear(512, 11)
        self.fc_bottom_color = nn.Linear(512, 11)
        self.fc_gender = nn.Linear(512, 2)
        self.fc_bag = nn.Linear(512, 2)
        self.fc_hat = nn.Linear(512, 2)

    def forward(self, x):
        features = self.backbone(x)
        features = features.view(features.size(0), -1)

        return {
            'top_color': self.fc_top_color(features),
            'bottom_color': self.fc_bottom_color(features),
            'gender': self.fc_gender(features),
            'bag': self.fc_bag(features),
            'hat': self.fc_hat(features)
        }

print(f"Device: {DEVICE}")
print("Carregando modelos...\n")

# EfficientNet
model_efficient = EfficientNetMultiTask()
model_efficient.load_state_dict(torch.load(MODEL_PATH_EFFICIENT, map_location=DEVICE))
model_efficient.to(DEVICE)
model_efficient.eval()
print("EfficientNet carregado!")

# ResNet18
model_resnet = ResNetMultiTask()
model_resnet.load_state_dict(torch.load(MODEL_PATH_RESNET, map_location=DEVICE))
model_resnet.to(DEVICE)
model_resnet.eval()
print("ResNet18 carregado!\n")


def preprocess_image(img_path):
    img = Image.open(img_path).convert("RGB")

    w, h = img.size
    if w != h:
        side = max(w, h)
        dw = (side - w) // 2
        dh = (side - h) // 2
        padding = (dw, dh, side - w - dw, side - h - dh)
        img = ImageOps.expand(img, padding, fill=0)

    img = img.resize((224, 224), Image.BILINEAR)

    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                           std=[0.229, 0.224, 0.225])
    ])

    img_tensor = transform(img)
    return img_tensor.unsqueeze(0)

def get_padded_image_for_display(img_path):
    img = Image.open(img_path).convert("RGB")

    w, h = img.size
    if w != h:
        side = max(w, h)
        dw = (side - w) // 2
        dh = (side - h) // 2
        padding = (dw, dh, side - w - dw, side - h - dh)
        img = ImageOps.expand(img, padding, fill=0)

    img = img.resize((224, 224), Image.BILINEAR)
    return img

def predict_with_model(model, img_tensor):
    with torch.no_grad():
        outputs = model(img_tensor)

    results = {}

    # Top Color
    top_probs = torch.softmax(outputs['top_color'], dim=1)[0]
    top_pred = top_probs.argmax().item()
    results['top_color'] = {
        'label': COLOR_LABELS[top_pred],
        'conf': top_probs[top_pred].item()
    }

    # Bottom Color
    bottom_probs = torch.softmax(outputs['bottom_color'], dim=1)[0]
    bottom_pred = bottom_probs.argmax().item()
    results['bottom_color'] = {
        'label': COLOR_LABELS[bottom_pred],
        'conf': bottom_probs[bottom_pred].item()
    }

    # Gender
    gender_probs = torch.softmax(outputs['gender'], dim=1)[0]
    gender_pred = gender_probs.argmax().item()
    results['gender'] = {
        'label': GENDER_LABELS[gender_pred],
        'conf': gender_probs[gender_pred].item()
    }

    # Bag
    bag_probs = torch.softmax(outputs['bag'], dim=1)[0]
    bag_pred = bag_probs.argmax().item()
    results['bag'] = {
        'label': BINARY_LABELS[bag_pred],
        'conf': bag_probs[bag_pred].item()
    }

    # Hat
    hat_probs = torch.softmax(outputs['hat'], dim=1)[0]
    hat_pred = hat_probs.argmax().item()
    results['hat'] = {
        'label': BINARY_LABELS[hat_pred],
        'conf': hat_probs[hat_pred].item()
    }

    return results

image_files = sorted([f for f in os.listdir(IMAGES_DIR)
                      if f.lower().endswith(('.jpg', '.jpeg', '.png'))])

print(f"Total de imagens: {len(image_files)}\n")
print("="*100)

for i, img_name in enumerate(image_files, 1):
    img_path = os.path.join(IMAGES_DIR, img_name)

    print(f"\n[{i}/{len(image_files)}] {img_name}")
    print("="*100)

    # Mostrar imagem
    img_display = get_padded_image_for_display(img_path)
    display(img_display)

    try:
        # Pré-processar
        img_tensor = preprocess_image(img_path).to(DEVICE)

        # Predições dos dois modelos
        results_efficient = predict_with_model(model_efficient, img_tensor)
        results_resnet = predict_with_model(model_resnet, img_tensor)

        # Preparar dados para tabela
        table_data = []
        attributes = ['top_color', 'bottom_color', 'gender', 'bag', 'hat']
        names = ['Cor Superior', 'Cor Inferior', 'Genero', 'Bolsa', 'Chapeu']

        for attr, name in zip(attributes, names):
            eff = results_efficient[attr]
            res = results_resnet[attr]

            # Determinar melhor
            if eff['conf'] > res['conf']:
                melhor = "EfficientNet"
                melhor_pred = f"{eff['label']} ({eff['conf']*100:.1f}%)"
            elif res['conf'] > eff['conf']:
                melhor = "ResNet18"
                melhor_pred = f"{res['label']} ({res['conf']*100:.1f}%)"
            else:
                melhor = "Empate"
                melhor_pred = f"{eff['label']} ({eff['conf']*100:.1f}%)"

            table_data.append([
                name,
                f"{eff['label']} ({eff['conf']*100:.1f}%)",
                f"{res['label']} ({res['conf']*100:.1f}%)",
                melhor,
                melhor_pred
            ])

        # Exibir tabela
        headers = ["Atributo", "EfficientNet", "ResNet18", "Vencedor", "Melhor Predicao"]
        print("\n" + tabulate(table_data, headers=headers, tablefmt="grid"))

    except Exception as e:
        print(f"Erro ao processar: {e}")

print("\n" + "="*100)
print("Processamento completo!")

"""## Vendo o gabarito"""

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
MODEL_PATH_EFFICIENT = '/content/drive/MyDrive/Ciência da Computação/Experiência Criativa: Projeto Transformador II/best_efficientnet_multitask.pth'
MODEL_PATH_RESNET = '/content/drive/MyDrive/Ciência da Computação/Experiência Criativa: Projeto Transformador II/best_multitask_resnet18_state.pth'
IMAGES_DIR = "/content/drive/MyDrive/Ciência da Computação/Experiência Criativa: Projeto Transformador II/imagens_qualidade_reduzida"
GABARITO_PATH = "/content/drive/MyDrive/Ciência da Computação/Experiência Criativa: Projeto Transformador II/gabarito_imagens.txt"

COLOR_LABELS = {
    0: "Preto", 1: "Branco", 2: "Vermelho", 3: "Roxo", 4: "Amarelo",
    5: "Cinza", 6: "Azul", 7: "Verde", 8: "Laranja", 9: "Marrom", 10: "Rosa"
}
GENDER_LABELS = {0: "Masculino", 1: "Feminino"}
BINARY_LABELS = {0: "Não", 1: "Sim"}

# Mapeamento para comparação com gabarito
COLOR_MAP = {
    "preto": "black", "branco": "white", "vermelho": "red", "roxo": "purple",
    "amarelo": "yellow", "cinza": "gray", "azul": "blue", "verde": "green",
    "laranja": "orange", "marrom": "brown", "rosa": "pink"
}

GENDER_MAP = {
    "masculino": "male", "feminino": "female",
    "homem": "male", "mulher": "female"
}

BINARY_MAP = {
    "sim": "present", "não": "not present",
    "com": "present", "sem": "not present"
}


def normalize_gabarito_value(value, attr_type):
    """Normaliza valor do gabarito para comparação"""
    value = value.strip().lower()

    if attr_type == 'color':
        for pt, en in COLOR_MAP.items():
            if pt in value:
                return en
    elif attr_type == 'gender':
        for pt, en in GENDER_MAP.items():
            if pt in value:
                return en
    elif attr_type == 'binary':
        if 'sem' in value or 'não' in value or 'nao' in value:
            return "not present"
        else:
            return "present"

    return value


def normalize_prediction(pred_label):
    """Normaliza predição do modelo para inglês"""
    pred_lower = pred_label.lower()

    # Cores
    if pred_lower in COLOR_MAP:
        return COLOR_MAP[pred_lower]

    # Gênero
    if pred_lower in GENDER_MAP:
        return GENDER_MAP[pred_lower]

    # Binário
    if pred_lower in BINARY_MAP:
        return BINARY_MAP[pred_lower]

    return pred_lower


def load_gabarito(gabarito_path):
    """Carrega o gabarito do arquivo txt"""
    gabarito = {}
    gabarito_original = {}
    try:
        with open(gabarito_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue

                parts = [p.strip() for p in line.split(',')]
                if len(parts) >= 6:
                    img_name = parts[0]
                    # Guardar valores normalizados para comparação
                    gabarito[img_name] = {
                        'top_color': normalize_gabarito_value(parts[1], 'color'),
                        'bottom_color': normalize_gabarito_value(parts[2], 'color'),
                        'gender': normalize_gabarito_value(parts[3], 'gender'),
                        'hat': normalize_gabarito_value(parts[4], 'binary'),
                        'bag': normalize_gabarito_value(parts[5], 'binary')
                    }
                    # Guardar valores originais em português padronizado para exibição
                    gabarito_original[img_name] = {
                        'top_color': parts[1].capitalize(),
                        'bottom_color': parts[2].capitalize(),
                        'gender': 'Feminino' if 'mulher' in parts[3].lower() or 'feminino' in parts[3].lower() else 'Masculino',
                        'hat': 'Sim' if 'com' in parts[4].lower() and 'sem' not in parts[4].lower() else 'Não',
                        'bag': 'Sim' if 'com' in parts[5].lower() and 'sem' not in parts[5].lower() else 'Não'
                    }
        print(f"Gabarito carregado: {len(gabarito)} imagens\n")
    except FileNotFoundError:
        print(f"Arquivo de gabarito não encontrado: {gabarito_path}\n")

    return gabarito, gabarito_original


class EfficientNetMultiTask(nn.Module):
    def __init__(self):
        super(EfficientNetMultiTask, self).__init__()
        efficientnet = models.efficientnet_b0(weights='IMAGENET1K_V1')
        self.backbone = nn.Sequential(*list(efficientnet.children())[:-1])

        self.fc_top_color = nn.Linear(1280, 11)
        self.fc_bottom_color = nn.Linear(1280, 11)
        self.fc_gender = nn.Linear(1280, 2)
        self.fc_bag = nn.Linear(1280, 2)
        self.fc_hat = nn.Linear(1280, 2)

    def forward(self, x):
        features = self.backbone(x)
        features = features.view(features.size(0), -1)

        return {
            'top_color': self.fc_top_color(features),
            'bottom_color': self.fc_bottom_color(features),
            'gender': self.fc_gender(features),
            'bag': self.fc_bag(features),
            'hat': self.fc_hat(features)
        }

class ResNetMultiTask(nn.Module):
    def __init__(self):
        super(ResNetMultiTask, self).__init__()
        resnet = models.resnet18(weights='IMAGENET1K_V1')
        self.backbone = nn.Sequential(*list(resnet.children())[:-1])

        self.fc_top_color = nn.Linear(512, 11)
        self.fc_bottom_color = nn.Linear(512, 11)
        self.fc_gender = nn.Linear(512, 2)
        self.fc_bag = nn.Linear(512, 2)
        self.fc_hat = nn.Linear(512, 2)

    def forward(self, x):
        features = self.backbone(x)
        features = features.view(features.size(0), -1)

        return {
            'top_color': self.fc_top_color(features),
            'bottom_color': self.fc_bottom_color(features),
            'gender': self.fc_gender(features),
            'bag': self.fc_bag(features),
            'hat': self.fc_hat(features)
        }

print(f"Device: {DEVICE}")
print("Carregando modelos...\n")

# EfficientNet
model_efficient = EfficientNetMultiTask()
model_efficient.load_state_dict(torch.load(MODEL_PATH_EFFICIENT, map_location=DEVICE))
model_efficient.to(DEVICE)
model_efficient.eval()
print("EfficientNet carregado!")

# ResNet18
model_resnet = ResNetMultiTask()
model_resnet.load_state_dict(torch.load(MODEL_PATH_RESNET, map_location=DEVICE))
model_resnet.to(DEVICE)
model_resnet.eval()
print("ResNet18 carregado!\n")

# Carregar gabarito
gabarito, gabarito_original = load_gabarito(GABARITO_PATH)


def preprocess_image(img_path):
    img = Image.open(img_path).convert("RGB")

    w, h = img.size
    if w != h:
        side = max(w, h)
        dw = (side - w) // 2
        dh = (side - h) // 2
        padding = (dw, dh, side - w - dw, side - h - dh)
        img = ImageOps.expand(img, padding, fill=0)

    img = img.resize((224, 224), Image.BILINEAR)

    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                           std=[0.229, 0.224, 0.225])
    ])

    img_tensor = transform(img)
    return img_tensor.unsqueeze(0)

def get_padded_image_for_display(img_path):
    img = Image.open(img_path).convert("RGB")

    w, h = img.size
    if w != h:
        side = max(w, h)
        dw = (side - w) // 2
        dh = (side - h) // 2
        padding = (dw, dh, side - w - dw, side - h - dh)
        img = ImageOps.expand(img, padding, fill=0)

    img = img.resize((224, 224), Image.BILINEAR)
    return img

def predict_with_model(model, img_tensor):
    with torch.no_grad():
        outputs = model(img_tensor)

    results = {}

    # Top Color
    top_probs = torch.softmax(outputs['top_color'], dim=1)[0]
    top_pred = top_probs.argmax().item()
    results['top_color'] = {
        'label': COLOR_LABELS[top_pred],
        'conf': top_probs[top_pred].item()
    }

    # Bottom Color
    bottom_probs = torch.softmax(outputs['bottom_color'], dim=1)[0]
    bottom_pred = bottom_probs.argmax().item()
    results['bottom_color'] = {
        'label': COLOR_LABELS[bottom_pred],
        'conf': bottom_probs[bottom_pred].item()
    }

    # Gender
    gender_probs = torch.softmax(outputs['gender'], dim=1)[0]
    gender_pred = gender_probs.argmax().item()
    results['gender'] = {
        'label': GENDER_LABELS[gender_pred],
        'conf': gender_probs[gender_pred].item()
    }

    # Bag
    bag_probs = torch.softmax(outputs['bag'], dim=1)[0]
    bag_pred = bag_probs.argmax().item()
    results['bag'] = {
        'label': BINARY_LABELS[bag_pred],
        'conf': bag_probs[bag_pred].item()
    }

    # Hat
    hat_probs = torch.softmax(outputs['hat'], dim=1)[0]
    hat_pred = hat_probs.argmax().item()
    results['hat'] = {
        'label': BINARY_LABELS[hat_pred],
        'conf': hat_probs[hat_pred].item()
    }

    return results

image_files = sorted([f for f in os.listdir(IMAGES_DIR)
                      if f.lower().endswith(('.jpg', '.jpeg', '.png'))])

print(f"Total de imagens: {len(image_files)}\n")
print("="*100)

# Contadores de acurácia
accuracy_stats = {
    'efficient': {'total': 0, 'correct': 0, 'by_attr': {'top_color': 0, 'bottom_color': 0, 'gender': 0, 'bag': 0, 'hat': 0}},
    'resnet': {'total': 0, 'correct': 0, 'by_attr': {'top_color': 0, 'bottom_color': 0, 'gender': 0, 'bag': 0, 'hat': 0}},
    'best': {'total': 0, 'correct': 0, 'by_attr': {'top_color': 0, 'bottom_color': 0, 'gender': 0, 'bag': 0, 'hat': 0}}
}

for i, img_name in enumerate(image_files, 1):
    img_path = os.path.join(IMAGES_DIR, img_name)

    print(f"\n[{i}/{len(image_files)}] {img_name}")
    print("="*100)

    # Mostrar imagem
    img_display = get_padded_image_for_display(img_path)
    display(img_display)

    try:
        # Pré-processar
        img_tensor = preprocess_image(img_path).to(DEVICE)

        # Predições dos dois modelos
        results_efficient = predict_with_model(model_efficient, img_tensor)
        results_resnet = predict_with_model(model_resnet, img_tensor)

        # Buscar gabarito (nome sem extensão)
        img_basename = os.path.splitext(img_name)[0]
        has_gabarito = img_basename in gabarito

        # Preparar dados para tabela
        table_data = []
        attributes = ['top_color', 'bottom_color', 'gender', 'bag', 'hat']
        names = ['Cor Superior', 'Cor Inferior', 'Genero', 'Bolsa', 'Chapeu']

        for attr, name in zip(attributes, names):
            eff = results_efficient[attr]
            res = results_resnet[attr]

            # Determinar melhor
            if eff['conf'] > res['conf']:
                melhor = "EfficientNet"
                melhor_pred = f"{eff['label']} ({eff['conf']*100:.1f}%)"
                best_label = eff['label']
            elif res['conf'] > eff['conf']:
                melhor = "ResNet18"
                melhor_pred = f"{res['label']} ({res['conf']*100:.1f}%)"
                best_label = res['label']
            else:
                melhor = "Empate"
                melhor_pred = f"{eff['label']} ({eff['conf']*100:.1f}%)"
                best_label = eff['label']

            # Gabarito
            gabarito_str = "-"
            if has_gabarito:
                gabarito_val = gabarito[img_basename][attr]
                gabarito_pt = gabarito_original[img_basename][attr]
                gabarito_str = gabarito_pt

                # Normalizar predições para comparação
                eff_normalized = normalize_prediction(eff['label'])
                res_normalized = normalize_prediction(res['label'])
                best_normalized = normalize_prediction(best_label)

                # Verificar acertos
                if eff_normalized == gabarito_val:
                    accuracy_stats['efficient']['by_attr'][attr] += 1

                if res_normalized == gabarito_val:
                    accuracy_stats['resnet']['by_attr'][attr] += 1

                if best_normalized == gabarito_val:
                    accuracy_stats['best']['by_attr'][attr] += 1

            table_data.append([
                name,
                f"{eff['label']} ({eff['conf']*100:.1f}%)",
                f"{res['label']} ({res['conf']*100:.1f}%)",
                melhor,
                melhor_pred,
                gabarito_str
            ])

        # Contar totais se há gabarito
        if has_gabarito:
            accuracy_stats['efficient']['total'] += len(attributes)
            accuracy_stats['resnet']['total'] += len(attributes)
            accuracy_stats['best']['total'] += len(attributes)

        # Exibir tabela
        headers = ["Atributo", "EfficientNet", "ResNet18", "Vencedor", "Melhor Predicao", "Gabarito"]
        print("\n" + tabulate(table_data, headers=headers, tablefmt="grid"))

    except Exception as e:
        print(f"Erro ao processar: {e}")

print("\n" + "="*100)
print("Processamento completo!")

# Exibir estatísticas de acurácia
if accuracy_stats['efficient']['total'] > 0:
    print("\n" + "="*100)
    print("ESTATÍSTICAS DE ACURÁCIA")
    print("="*100)

    for model_name, stats in [('EfficientNet', accuracy_stats['efficient']),
                               ('ResNet18', accuracy_stats['resnet']),
                               ('Melhor Modelo', accuracy_stats['best'])]:
        total_correct = sum(stats['by_attr'].values())
        overall_acc = (total_correct / stats['total'] * 100) if stats['total'] > 0 else 0

        print(f"\n{model_name}:")
        print(f"  Acurácia Geral: {overall_acc:.2f}% ({total_correct}/{stats['total']})")
        print(f"  Por Atributo:")

        attr_names = {'top_color': 'Cor Superior', 'bottom_color': 'Cor Inferior',
                      'gender': 'Gênero', 'bag': 'Bolsa', 'hat': 'Chapéu'}

        for attr, correct in stats['by_attr'].items():
            total_attr = len([g for g in gabarito.values() if attr in g])
            acc = (correct / total_attr * 100) if total_attr > 0 else 0
            print(f"    {attr_names[attr]}: {acc:.2f}% ({correct}/{total_attr})")